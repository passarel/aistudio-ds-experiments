{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08273209-05d9-4f71-88ce-ab78d470d679",
   "metadata": {},
   "source": [
    "Dataset source: https://huggingface.co/datasets/b-mc2/sql-create-context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68477a05-3635-4c08-ad22-59776322d8b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Extra libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e689650-3087-4ffa-bce5-4089af43fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install peft\n",
    "!pip install trl\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a6f57-6753-4111-bf17-7233ea2994dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1fe6e3-0168-491a-b2bc-97934c755570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 16:09:17.770849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 16:09:19.771366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel, AutoPeftModelForCausalLM\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721a1b1-d378-4698-a68f-5d5f32ce637d",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00378e4f-7de0-4d38-86b3-39935b6ec439",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00db2b54-1f31-4139-aafc-6efc96ec1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_DATASETS_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c3e01-399e-47c6-a5ab-e9207d3c4d11",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04cf66d-1866-46f9-8087-a9cb48c08194",
   "metadata": {},
   "source": [
    "Each of the 78,577 data points consists of a natural language query, corresponding SQL CREATE TABLE statements, and then the SQL query corresponding to the natural language question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "216c35aa-1aaa-456e-9bb0-b043528d8382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776e42e0243c4878869b73b9fbc184d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a32b81d6d04e499c6d708bae8f4be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f97668ccea4c0896505b63110a9d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"b-mc2/sql-create-context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f28a78-0013-4dfa-a7b5-370be5ff5861",
   "metadata": {},
   "source": [
    "#### Taking a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5808db81-3613-4b42-8345-5b19ddae7c97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 78577\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43d01dbd-a3ea-48c0-9f2b-96be3a6f6b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many heads of the departments are older than 56 ?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdb42fbf-4180-4434-ae95-ac59c9f22b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE head (age INTEGER)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "607a6c1c-36c6-41d8-941f-d0a7dab3d3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM head WHERE age > 56'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['answer'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e6b0b-5629-45c0-b205-59df0d4b5425",
   "metadata": {},
   "source": [
    "One issue specific to this dataset was incorrect ground truth SQL outputs that had to be filtered out. In many data points, attributes that were integers were labeled as VARCHARs in the CREATE TABLE statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1ddd7-4088-43af-9045-989cc8edc819",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa17c3f-e88d-4cfd-bd82-e4c4b4fc27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair os tipos de colunas do contexto\n",
    "def extract_column_types(context):\n",
    "    column_type_pattern = re.compile(r'(\\w+)\\s+(INTEGER|VARCHAR)')\n",
    "    return dict(column_type_pattern.findall(context))\n",
    "\n",
    "# Função para verificar inconsistências no tipo de dados no answer\n",
    "def is_inconsistent(context, answer):\n",
    "    column_types = extract_column_types(context)\n",
    "    # Regex para encontrar condições que usam números ou operações matemáticas no answer\n",
    "    conditions_with_numbers_pattern = re.compile(\n",
    "        r'(\\w+)\\s*(<=|>=|<>|!=|=|<|>|\\+|-|\\*|\\/)\\s*(\\d+|\\w+)')\n",
    "    for match in conditions_with_numbers_pattern.finditer(answer):\n",
    "        column, operator, value = match.groups()\n",
    "        # Verificar se a coluna é do tipo VARCHAR\n",
    "        if column_types.get(column, 'INTEGER') == 'VARCHAR':\n",
    "            # Checar se a condição envolve um número diretamente ou uma outra coluna que deveria ser INTEGER\n",
    "            if value.isdigit() or (value.isalpha() and column_types.get(value, 'VARCHAR') == 'INTEGER'):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b5cf69b-2997-4985-97bb-8a4ac5e46b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6110a74460af4f96a1443512c220045e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar as amostras inconsistentes\n",
    "consistent_dataset = dataset.filter(lambda example: not is_inconsistent(example['context'], example['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1df5194-c8eb-4475-800d-11e1ec13bb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer'],\n",
       "        num_rows: 59890\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consistent_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4035a8-a139-46bb-a3e2-f976a67982a7",
   "metadata": {},
   "source": [
    "#### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9eaa62c-95a2-42d7-87a4-aec47ad3fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset = consistent_dataset['train'].shuffle(seed=42).select(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad9c69e1-24db-4718-84d6-e4d6a436b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a443e95-2fd6-4cf4-8379-63c7364f457b",
   "metadata": {},
   "source": [
    "### Prompt setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d79efc2-3050-4426-bd78-2b144453b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Translate the provided natural language question into an accurate and appropriate SQL query.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d144941-d3e2-414e-9aa3-67054e13a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_prompt(\n",
    "    question: str, answer: str, context: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### Instruction: {system_prompt}\n",
    "\n",
    "### Input:\n",
    "{question.strip()}\n",
    "### Database schema\n",
    "{context.strip()}\n",
    "### Response:\n",
    "{answer}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9019cfb0-0f47-407f-aad6-64e8f3091036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(data_point):\n",
    "    return {\n",
    "        \"question\": data_point['question'],\n",
    "        \"answer\": data_point['answer'],\n",
    "        \"context\": data_point['context'],\n",
    "        \"text\": generate_training_prompt(data_point['question'],\n",
    "                                         data_point['answer'],\n",
    "                                         data_point['context']),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73ccfbbe-794f-4389-b09b-40f251ee99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = generate_text(reduced_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "356725f6-e677-4fe3-aa90-b5f349b7c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: Translate the provided natural language question into an accurate and appropriate SQL query.\n",
      "\n",
      "### Input:\n",
      "Name the least dismissals for sammy carter\n",
      "### Database schema\n",
      "CREATE TABLE table_23316034_23 (dismissals INTEGER, player VARCHAR)\n",
      "### Response:\n",
      "SELECT MIN(dismissals) FROM table_23316034_23 WHERE player = \"Sammy Carter\"\n"
     ]
    }
   ],
   "source": [
    "print(example[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d866afc-439d-45fb-ad2b-ed501e5c4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(data: Dataset):\n",
    "    return (data.shuffle(seed=42).map(generate_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f968a68-09a3-4ecb-bcda-8eacd5778884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0603ccbb0a84687a93359a30e808c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_dataset = process_dataset(reduced_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcb786fd-cce5-403a-9dc7-dbe01deee09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'List all information about courses sorted by credits in the ascending order.',\n",
       " 'context': 'CREATE TABLE COURSE (Credits VARCHAR)',\n",
       " 'answer': 'SELECT * FROM COURSE ORDER BY Credits',\n",
       " 'text': '### Instruction: Translate the provided natural language question into an accurate and appropriate SQL query.\\n\\n### Input:\\nList all information about courses sorted by credits in the ascending order.\\n### Database schema\\nCREATE TABLE COURSE (Credits VARCHAR)\\n### Response:\\nSELECT * FROM COURSE ORDER BY Credits'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5d4e-04f3-4338-9a50-ecb60d733685",
   "metadata": {},
   "source": [
    "### Spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "071e7771-00de-4c5b-b17d-9703ca2cd277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = processed_dataset.select(range(4000))\n",
    "valid_dataset = processed_dataset.select(range(4000, len(processed_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "200902ce-1dfb-4f65-83b8-529894c8cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'context', 'answer', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar um novo DatasetDict com os conjuntos de treino e validação\n",
    "split_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': valid_dataset\n",
    "})\n",
    "\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60700e91-788a-416e-bc71-da3d3107aa13",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9970271-4854-4e51-b36c-2adf494702a0",
   "metadata": {},
   "source": [
    "### Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b009ae-07f4-433d-b133-e2f2a5ab733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aabdf22290451da649c3390d9058f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447bca3d-34ce-4a24-ba00-f90b6bec26f4",
   "metadata": {},
   "source": [
    "#### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9448a18a-3c49-4266-b713-8afb41883a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_safetensors=True,\n",
    "        quantization_config=bnb_config,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\"\n",
    "        \n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbdb2acf-2142-4f08-bffb-5baff2d31ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f064c68ce341eda308092e334f8044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f140caa8e04dd1b3dbae05f3a10629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8015fc8d6c14635b733763febf67810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a2e7f254a64ceda78daa71e7872abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a94388e2588447a9f3f1b9be85b0e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = create_model_and_tokenizer()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57a2009-7c29-44f0-a0b3-e3969ab2a41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " 'load_in_8bit': False,\n",
       " 'load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': False,\n",
       " 'bnb_4bit_compute_dtype': 'float16'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ca5564b-b988-4bee-9fa9-f60c290653ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfc897-9bb9-4958-9c87-67996526222f",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8331771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_EXPERIMENT_NAME'] = 'llama2-finetune-quant4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1afc98-171f-449a-8d20-a53b1e0b4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir='./output',\n",
    "    report_to=\"mlflow\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03395e7b-5470-426e-a39c-544ceb7fea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf614ce221640019b1ded522df2be66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5000559d0346b78a4418f0e35075d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb694102-85d8-48cb-9067-20fa9c34d0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/16 18:56:26 INFO mlflow.tracking.fluent: Experiment with name 'llama2-finetune-quant4' does not exist. Creating a new experiment.\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 2:13:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.597300</td>\n",
       "      <td>0.632874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.463600</td>\n",
       "      <td>0.617069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.485200</td>\n",
       "      <td>0.578498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.581486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.579682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "mlflow.log_metric(\"training_time\", training_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d36e97f-2d22-4f54-95ef-6ae7f3b564f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212dd2d-9220-4ac7-a989-04e713a9770e",
   "metadata": {},
   "source": [
    "### Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8526fb90-66b0-4e67-9278-8ddad7bc3c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1140231bec8480fa39de469d0c61dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f3e676bea945bba9f3d36ce65e9e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c3adb2ce554f958cfb98e771b57cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0453b8c6343e4224ab30e9fd6aba8629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab17e6749eb41349ca3a62121d9e82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675b6714a32147ecbfef7a503aff9ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30f8a0efcc54ff5bbd41773ca1b1e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    './output',\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e61b977-b755-4db3-a1d8-0b21e045eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = trained_model.base_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5240e78f-5e69-403a-993b-2704dc9afcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.save_pretrained('merged_model', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "025cecf8-845f-4be5-96a7-54a39ebb1521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('merged_model/tokenizer_config.json',\n",
       " 'merged_model/special_tokens_map.json',\n",
       " 'merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"merged_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3a802-bed2-48e4-82d6-1cbcafee1ee9",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "017a4812-5905-47da-9bd9-217faee6b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(model, text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.0001)\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c589bab-edf3-421e-ba68-91e55e632f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e77029130443ddbc4947d6f8d76c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = create_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a5c5fd6-6bc9-4c17-adcf-4c3887303e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, './output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d3486c6-0b3d-4f47-8db6-38f0b04b421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction: Translate the provided natural language question into an accurate and appropriate SQL query.\\n\\n### Input:\\nWhat is Winner, when Dates is Dec 11-14?\\n### Database schema\\nCREATE TABLE table_name_18 (winner VARCHAR, dates VARCHAR)\\n### Response:\\nSELECT winner FROM table_name_18 WHERE dates = \"dec 11-14\"'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset['text'][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5e3eb55-1798-4779-aa29-cff5432c7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(model, valid_dataset['text'][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "245260b6-a544-40d7-8a24-375464e09d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### Output:',\n",
       " 'Winner',\n",
       " '',\n",
       " '### Explanation:',\n",
       " '',\n",
       " '### Example:',\n",
       " '',\n",
       " '### Input:',\n",
       " 'What is Winner, when Dates is Dec 11-14?',\n",
       " '',\n",
       " '### Output:',\n",
       " 'Winner',\n",
       " '',\n",
       " '### Explanation:',\n",
       " '',\n",
       " '### Example:',\n",
       " '',\n",
       " '### Input:',\n",
       " 'What is Winner, when Dates is Dec 11-14?',\n",
       " '',\n",
       " '### Output:',\n",
       " 'Winner',\n",
       " '',\n",
       " '### Explanation:',\n",
       " '',\n",
       " '### Example:',\n",
       " '',\n",
       " '### Input:',\n",
       " 'What is Winner, when Dates is Dec 11-14?',\n",
       " '',\n",
       " '### Output:',\n",
       " 'Winner',\n",
       " '',\n",
       " '### Explanation:',\n",
       " '',\n",
       " '### Example:',\n",
       " '',\n",
       " '### Input:',\n",
       " 'What is Winner, when Dates is Dec 11-14?',\n",
       " '',\n",
       " '### Output:',\n",
       " 'Winner',\n",
       " '',\n",
       " '### Explanation:',\n",
       " '',\n",
       " '### Example:',\n",
       " '',\n",
       " '### Input:',\n",
       " 'What is Winner, when Dates is Dec 11-14?',\n",
       " '',\n",
       " '### Output:',\n",
       " 'Winner',\n",
       " '',\n",
       " '### Explanation:',\n",
       " '',\n",
       " '###']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec33e4-54b8-48ed-a5d7-77c2edd8c8d7",
   "metadata": {},
   "source": [
    "### TODO: NEED TO IMPROVE RESULTS ASAP!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
