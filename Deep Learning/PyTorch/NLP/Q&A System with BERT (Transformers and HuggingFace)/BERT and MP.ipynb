{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5db692c-89b6-4757-8849-5dfb179a7b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m403.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2023.12.2 huggingface-hub-0.20.3 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.1 transformers-4.37.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b853f387-e023-46f8-bb01-a7db1049e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 12:10:14.879485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 12:10:16.464507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import torch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ec4fd5-0354-4be5-9c63-a0896d0fa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\n",
    "    'question-answering',\n",
    "    model='./distilbert_bertqa',\n",
    "    device=-1 #0->GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e590e0-8a3c-490e-88e1-90bf2e2bb2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6935740113258362,\n",
       " 'start': 8,\n",
       " 'end': 37,\n",
       " 'answer': 'Phoenix will be so successful'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"I think Phoenix will be so successful, don't you think?\"\n",
    "question = \"What does she said about Phoenix?\"\n",
    "qa(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764ffd49-bcfe-40e8-b871-b1bbd111d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBERTModel(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def _preprocess(self, inputs):\n",
    "        context = inputs['context']\n",
    "        question = inputs['question']\n",
    "        return context, question\n",
    "        \n",
    "    def load_context(self, device=-1):\n",
    "        self.model = pipeline(\n",
    "            'question-answering',\n",
    "             model='./distilbert_bertqa',\n",
    "             device=device\n",
    "        )\n",
    "        print('Carreguei')\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        context, question = _preprocess(inputs)\n",
    "        output = self.model(context, question)\n",
    "        return output\n",
    "\n",
    "    @classmethod\n",
    "    def log_model(cls, model, base_path, model_name): #eg (model, '', 'my_model')\n",
    "        torch_model_path = os.path.join(base_path, model_name)\n",
    "        requirements = [\n",
    "            \"transformers==4.37.0\",\n",
    "            \"mlflow==2.5.0\",\n",
    "            \"numpy==1.24.3\",\n",
    "            \"torch==2.0.0\",\n",
    "            \"tqdm==4.65.0\",\n",
    "        ]\n",
    "        mlflow.pyfunc.log_model(\n",
    "            model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts={\"model\": model_name},\n",
    "            pip_requirements=requirements\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "068e7577-3629-45bd-8015-afd01713ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/phoenix/mlflow/504731225219629820', creation_time=1705969426272, experiment_id='504731225219629820', last_update_time=1705969426272, lifecycle_stage='active', name='test_bertqa', tags={}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name='test_bertqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0280d55-cabc-4ade-a0f7-5b238891c0c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3e5c614726c643d992d06726a14fcfd9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb5dc8f008f43a0a7822207bfea2d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'distilbert_bertqa' already exists. Creating a new version of this model...\n",
      "2024/01/23 12:22:51 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: distilbert_bertqa, version 3\n",
      "Created version '3' of model 'distilbert_bertqa'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='distilbert_bertqa') as run:\n",
    "    print(run.info.run_id)\n",
    "    DistilBERTModel.log_model(model=qa, base_path='./', model_name='distilbert_bertqa')\n",
    "    mlflow.register_model(model_uri = f\"runs:/{run.info.run_id}/distilbert_bertqa\", name=\"distilbert_bertqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34988d15-c34e-4ffa-950c-7d26e7476571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RunInfo: artifact_uri='/phoenix/mlflow/504731225219629820/3e5c614726c643d992d06726a14fcfd9/artifacts', end_time=None, experiment_id='504731225219629820', lifecycle_stage='active', run_id='3e5c614726c643d992d06726a14fcfd9', run_name='distilbert_bertqa', run_uuid='3e5c614726c643d992d06726a14fcfd9', start_time=1706012563077, status='RUNNING', user_id='root'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60645fa1-9448-438c-8956-4e3a5bb831e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/click/core.py:2362: UserWarning: Use of conda is discouraged. If you use it, please ensure that your use of conda complies with Anaconda's terms of service (https://legal.anaconda.com/policies/en/?name=terms-of-service). virtualenv is the recommended tool for environment reproducibility. To suppress this warning, set the MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING environment variable to 'TRUE'.\n",
      "  value = self.callback(ctx, self, value)\n",
      "Downloading artifacts: 100%|█████████████████████| 1/1 [00:00<00:00, 132.13it/s]\n",
      "2024/01/23 12:23:10 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2024/01/23 12:23:12 INFO mlflow.utils.conda: === Creating conda environment mlflow-cb3037257d688284e46da00970c6ac7ed000bf81 ===\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... "
     ]
    }
   ],
   "source": [
    "!mlflow models serve -m /phoenix/mlflow/504731225219629820/3e5c614726c643d992d06726a14fcfd9/artifacts/distilbert_bertqa --env-manager conda --port 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414b55e-2a87-4927-88b3-0babc929c78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
