{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e77931-e698-41ed-a5dd-7bd079df3a0d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c998f3-f291-49e3-851e-e04441468de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2ac6b-5872-4088-a470-47e331485e92",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8aa38-6d65-4610-b7f6-9ebfd317fe90",
   "metadata": {},
   "source": [
    "The MNIST dataset is comprised of 70,000 handwritten numeric digit images and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde7f29-5ca8-4e7b-9464-927fd240b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='./', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cb759-dff4-44e1-a0b2-5a4b3c0eb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297a3b8-5304-407a-af88-a2911e302f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08d0db-9791-4781-a0af-706fe1abc773",
   "metadata": {},
   "source": [
    "### Create loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59690a52-5bc0-4de2-bfc1-1b1e325b46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45519b7-6cd4-4873-8c73-a18b6d1e33d7",
   "metadata": {},
   "source": [
    "## Define a convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5906d7-0e0a-4225-8268-8d106f93360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers\n",
    "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99321d1a-ef3a-4852-a982-4e776c401452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first MNIST record\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb6cf3-d6cd-445f-95d9-1e6ff24ec045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rank-4 tensor to be passed into the model\n",
    "# (train_loader will have done this already)\n",
    "x = X_train.view(1,1,28,28)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344606e8-eea6-4d22-8fe4-de543097965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the first convolution/activation\n",
    "x = F.relu(conv1(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a01c9f-7535-4ef0-ba81-81aad4abb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the first pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755aa3a-24fa-4aad-8010-10d7b5f9f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the second convolution/activation\n",
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f8d5b-e66d-4250-825c-3d0128796c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the second pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970f90c-d268-4e9e-a090-0da6d47c0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data\n",
    "x = x.view(-1, 5*5*16)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a7506-4341-4d04-8a39-d1603a2bacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dae639-76bc-47fc-8f69-a1971c25107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e175201-8ee7-4cce-a87f-c73bded37f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c420a-b7eb-42f6-b219-d3dc05bf9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ae219-46b7-4e8d-a9ec-c653091315e9",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca254784-e5d4-4c90-81cd-c91b1878ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0899b6a-d63a-4497-bc3b-4db0871bce04",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654effda-2b7b-4571-bf0c-40cb56544d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/phoenix/tensorboard/'\n",
    "writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7816c88-bf08-40e9-9bfc-0565af0fda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2e529-4857-4407-8562-eaae7ecff4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o número de épocas\n",
    "epochs = 5\n",
    "\n",
    "# Listas para armazenar perdas e acertos\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "# Inicialize o SummaryWriter do TensorFlow\n",
    "log_dir = '/phoenix/tensorboard/tensorlogs'\n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Loop sobre as épocas\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    # Loop sobre os batches de treinamento\n",
    "    for b, (X_train, y_train) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # Aplicar o modelo\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        # Calcular as previsões corretas\n",
    "        predicted = torch.max(y_pred, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr.item()\n",
    "\n",
    "        # Atualizar os parâmetros\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Imprimir resultados intermediários\n",
    "        if b % 600 == 0:\n",
    "            print(f'epoch: {i+1:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  accuracy: {trn_corr*100/(10*b):7.3f}%')\n",
    "\n",
    "    # Armazenar perdas e acertos de treinamento\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    # Loop sobre os batches de teste\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum().item()\n",
    "\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "\n",
    "    # Gravar métricas no MLflow\n",
    "    with mlflow.start_run(run_name=f\"Run {i + 1}\") as run:\n",
    "        print(run.info.run_id)\n",
    "        mlflow.log_metric('train_loss', loss.item())\n",
    "        mlflow.log_metric('train_accuracy', trn_corr*100/len(train_loader.dataset))\n",
    "        mlflow.log_metric('test_loss', loss.item())\n",
    "        mlflow.log_metric('test_accuracy', tst_corr*100/len(test_loader.dataset))\n",
    "    # Gravar métricas no TensorBoard\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar('training_accuracy', trn_corr*100/(10*len(train_loader)), step=i+1)\n",
    "        tf.summary.scalar('validation_accuracy', tst_corr*100/len(test_loader.dataset), step=i+1)\n",
    "\n",
    "# Fechar o SummaryWriter\n",
    "writer.close()\n",
    "\n",
    "# Finalizar a execução do MLflow\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e15060-3c31-4611-981d-4f0b3bd85b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([t/600 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='validation accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e4e84-5b25-4aaa-b1e1-0a43ddb4f1ef",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b921ec6-e03c-4616-b417-a4510b7039a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data all at once, not in batches\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d33219-cd1a-4faa-a128-44d413719c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        y_val = model(X_test)  # we don't flatten the data this time\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "print(f'Test accuracy: {correct.item()}/{len(test_data)} = {correct.item()*100/(len(test_data)):7.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194a76c-0d38-4bb0-be19-415fa261835e",
   "metadata": {},
   "source": [
    "## Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195770fa-a0f8-40b7-b443-7b2d0dff0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "print(confusion_matrix(predicted.view(-1), y_test.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddf84b-f0f0-4f6d-9d8d-2558f7c9e57a",
   "metadata": {},
   "source": [
    "## Examine the misses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3822bb2-e405-449f-be81-0cf71a2e612c",
   "metadata": {},
   "source": [
    "We can track the index positions of \"missed\" predictions, and extract the corresponding image and label. We'll do this in batches to save screen space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010dd99-13b8-40c7-a460-10eb6c309808",
   "metadata": {},
   "outputs": [],
   "source": [
    "misses = np.array([])\n",
    "for i in range(len(predicted.view(-1))):\n",
    "    if predicted[i] != y_test[i]:\n",
    "        misses = np.append(misses,i).astype('int64')\n",
    "        \n",
    "# Display the number of misses\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5a0e5-9536-4ad9-ace0-2071ff140607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 index positions\n",
    "misses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653190a-3494-4f41-ad23-cdadc88b6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator to feed batched rows\n",
    "r = 12   # row size\n",
    "row = iter(np.array_split(misses,len(misses)//r+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b451d-b1ad-44ca-9a0d-0553264c1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextrow = next(row)\n",
    "print(\"Index:\", nextrow)\n",
    "print(\"Label:\", y_test.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "print(\"Guess:\", predicted.index_select(0,torch.tensor(nextrow)).numpy())\n",
    "\n",
    "images = X_test.index_select(0,torch.tensor(nextrow))\n",
    "im = make_grid(images, nrow=r)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(np.transpose(im.numpy(), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4152c-786b-4863-8dc5-f7d438ed47c5",
   "metadata": {},
   "source": [
    "## Run a new image through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1997f-7513-4901-91e0-7089ab5ad9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2019\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(test_data[x][0].reshape((28,28)), cmap=\"gist_yarg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7159c8e-bdcc-4d44-86e3-d38653e337ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[x][0].view(1,1,28,28)).argmax()\n",
    "print(\"Predicted value:\",new_pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bace4-a8c3-437e-ae4b-3b3e3f1242e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e0b6e-7304-4bf3-9bdd-32997a6f8696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc2247-92e6-4271-86e8-54e5b4c905d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
